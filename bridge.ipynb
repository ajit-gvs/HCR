{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bridge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOntRG185jRaQQ2yyvC4w1/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit-gvs/HCR/blob/master/bridge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIPwgx7m3ePZ"
      },
      "source": [
        "def create_placeholders(input_H, input_W, no_channels, no_classes):\r\n",
        "\r\n",
        "    X = tf.placeholder(tf.float32, shape=(None, input_H, input_W, no_channels), name=\"X\")\r\n",
        "    Y = tf.placeholder(tf.float32, shape=(None, no_classes), name=\"Y\")\r\n",
        "    \r\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVXRfsmD4glD"
      },
      "source": [
        "def initialize_parameters():\r\n",
        "    \r\n",
        "    W1 = tf.get_variable(\"W1\", [4, 4, 3, 32], initializer = tf.contrib.layers.xavier_initializer())\r\n",
        "    W2 = tf.get_variable(\"W2\", [2, 2, 32, 32], initializer = tf.contrib.layers.xavier_initializer())\r\n",
        "\r\n",
        "    parameters = {\"W1\": W1,\r\n",
        "                  \"W2\": W2}\r\n",
        "   \r\n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Jbi_k5_SKC"
      },
      "source": [
        "def buildCNN(X):\r\n",
        "  # list of parameters for the layers\r\n",
        "  kernelVals = [5, 5, 3, 3, 3]\r\n",
        "  featureVals = [1, 32, 64, 128, 128, 256]\r\n",
        "  strideVals = poolVals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\r\n",
        "  numLayers = len(strideVals)\r\n",
        "\r\n",
        "        # create layers\r\n",
        "  pool = cnn_input  # input to first CNN layer\r\n",
        "  for i in range(numLayers+1):\r\n",
        "    if i<=4:\r\n",
        "      kernel = tf.Variable(tf.random.truncated_normal([kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]],\r\n",
        "                                           stddev=0.1))\r\n",
        "      conv = tf.nn.conv2d(input=pool, filters=kernel, padding='SAME', strides=(1,1,1, 1))\r\n",
        "      relu = tf.nn.relu(conv)\r\n",
        "      conv_norm = tf.compat.v1.layers.batch_normalization(relu, training=self.is_train)\r\n",
        "      pool = tf.nn.max_pool2d(input=pool, ksize=( poolVals[i][0], poolVals[i][1]),\r\n",
        "                                        strides=( 1,strideVals[i][0], strideVals[i][1],1), padding='VALID')\r\n",
        "    else:\r\n",
        "      flatten=tf.compat.v1.layers.flatten(pool)\r\n",
        "      dense=tf.compat.v1.layers.dense(flatten)\r\n",
        "      relu = tf.nn.relu(dense)\r\n",
        "      dense_norm = tf.compat.v1.layers.batch_normalization(relu, training=self.is_train)\r\n",
        "      output_dense=tf.compat.v1.layers.dense(dense_norm)\r\n",
        "  return output_dense\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTz5mZqUN_4P"
      },
      "source": [
        "def compute_cost(Z3, Y):\r\n",
        "\r\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\r\n",
        "    \r\n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHwYxXlw74e"
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64):\r\n",
        "    # number of training examples\r\n",
        "    m = X.shape[0]                  \r\n",
        "    mini_batches = []\r\n",
        "    \r\n",
        "    # Step 1: Shuffle (X, Y)\r\n",
        "    permutation = list(np.random.permutation(m))\r\n",
        "    shuffled_X = X[permutation,:,:,:]\r\n",
        "    shuffled_Y = Y[permutation,:]\r\n",
        "\r\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\r\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\r\n",
        "    for k in range(0, num_complete_minibatches):\r\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\r\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "    \r\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\r\n",
        "    if m % mini_batch_size != 0:\r\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\r\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\r\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\r\n",
        "        mini_batches.append(mini_batch)\r\n",
        "    \r\n",
        "    return mini_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBNcIQXCxC9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}