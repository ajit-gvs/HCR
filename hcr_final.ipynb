{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMND5HLS7opv2i26VvVQh64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit-gvs/HCR/blob/master/hcr_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg3pyEH1n3BP"
      },
      "source": [
        "\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.__version__)\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from PIL import Image\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from PIL import ImageFile\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuL7UImvJY_"
      },
      "source": [
        "def image_binarization(image):\r\n",
        "  # converting image to grayscale\r\n",
        "  image_grayscale=image.convert('L')\r\n",
        "  img=np.array(image_grayscale) \r\n",
        "   \r\n",
        "  img[img <128] = 0\r\n",
        "  img[img >=128] = 254 \r\n",
        "\r\n",
        "  #making white as foreground pixels and black as background pixels\r\n",
        "  img[img==0]=255\r\n",
        "  img[img==254]=0\r\n",
        "  \r\n",
        "  return img\r\n",
        "\r\n",
        "\r\n",
        "def line_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  end_matrix=[]\r\n",
        "\r\n",
        "  #matrix to get the start and end points of a line\r\n",
        "  \r\n",
        "  lines=[]\r\n",
        "  begin_matrix=[]\r\n",
        "  stop_matrix=[]\r\n",
        "  del_start_matrix=[]\r\n",
        "  del_end_matrix=[]\r\n",
        "\r\n",
        "  horizontal_hist = np.sum(img,axis=1,keepdims=True)/255\r\n",
        "  start_count=0\r\n",
        "\r\n",
        "  for i in range(len(horizontal_hist)):\r\n",
        "\r\n",
        "    if horizontal_hist[i]>0 and horizontal_hist[i-1]==0:\r\n",
        "      start_count+=1\r\n",
        "      start_matrix.append(i)\r\n",
        "\r\n",
        "    if horizontal_hist[i]==0 and start_count>0 and horizontal_hist[i-1]>0:\r\n",
        "      end_matrix.append(i)\r\n",
        "\r\n",
        "  \r\n",
        "  \r\n",
        "  if len(start_matrix)==len(end_matrix):\r\n",
        "    for i in range(len(start_matrix)):\r\n",
        "      if end_matrix[i]-start_matrix[i]<20:\r\n",
        "        del_start_matrix.append(i)\r\n",
        "        del_end_matrix.append(i)\r\n",
        "    for i in range(len(start_matrix)):\r\n",
        "      count=0\r\n",
        "      for j in range(len(del_start_matrix)):\r\n",
        "        if i==del_start_matrix[j]:\r\n",
        "          count=count+1\r\n",
        "      if count==0:\r\n",
        "        begin_matrix.append(start_matrix[i])\r\n",
        "    for i in range(len(end_matrix)):\r\n",
        "      count=0\r\n",
        "      for j in range(len(del_end_matrix)):\r\n",
        "        if i==del_end_matrix[j]:\r\n",
        "          count=count+1\r\n",
        "      if count==0:\r\n",
        "        stop_matrix.append(end_matrix[i])\r\n",
        "    \r\n",
        "    for i in range(len(begin_matrix)):\r\n",
        "      lines.append(img[begin_matrix[i]:stop_matrix[i],:])\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "  \r\n",
        "  return lines\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def word_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  end_matrix=[]\r\n",
        "\r\n",
        "  #matrix to get the start and end points of a word\r\n",
        "  dissection_matrix=[]\r\n",
        "  \r\n",
        "  words=[]\r\n",
        "  m,n=img.shape\r\n",
        "  \r\n",
        "  length=[]\r\n",
        "  vertical_hist = np.sum(img,axis=0,keepdims=True)/255\r\n",
        "  \r\n",
        "  \r\n",
        "  start_count=0\r\n",
        "  \r\n",
        "  \r\n",
        "  for i in range(len(vertical_hist[0])):\r\n",
        "    if vertical_hist[0][i]>0 and vertical_hist[0][i-1]==0:\r\n",
        "      start_count+=1\r\n",
        "      start_matrix.append(i)\r\n",
        "    if vertical_hist[0][i]==0 and start_count>0 and vertical_hist[0][i-1]>0:\r\n",
        "      end_matrix.append(i)\r\n",
        "  \r\n",
        "  \r\n",
        "  length_mag=0\r\n",
        "  for i in range(len(start_matrix)):\r\n",
        "    if i>0:\r\n",
        "      length_mag=(start_matrix[i]-end_matrix[i-1])\r\n",
        "      length.append(length_mag)\r\n",
        "\r\n",
        "  max=np.max(length)\r\n",
        "     \r\n",
        "  avg=max/3\r\n",
        "\r\n",
        "  dissection_matrix.append([start_matrix[0],end_matrix[0]])\r\n",
        "  j=0\r\n",
        "  for i in range(len(length)-1):\r\n",
        "    \r\n",
        "    if length[i]> avg:\r\n",
        "      dissection_matrix.append([start_matrix[i+1],end_matrix[i+1]])\r\n",
        "      j=j+1\r\n",
        "      \r\n",
        "    if length[i]<=avg:\r\n",
        "      dissection_matrix[j][1]=end_matrix[i+1]\r\n",
        "  for i in range(len(dissection_matrix)):\r\n",
        "    \r\n",
        "    words.append(img[0:m,dissection_matrix[i][0]:dissection_matrix[i][1]])\r\n",
        "  \r\n",
        "  return words\r\n",
        "\r\n",
        "\r\n",
        "def char_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  dissection_matrix=[]\r\n",
        "  delete_matrix=[]\r\n",
        "  address_matrix=[]\r\n",
        "  \r\n",
        "  \r\n",
        "  characters=[]\r\n",
        "  m,n=img.shape\r\n",
        "\r\n",
        "  vertical_hist = np.sum(img,axis=0,keepdims=True)/255\r\n",
        "  start_matrix.append(0)\r\n",
        "\r\n",
        "  for i in range(len(vertical_hist[0])):\r\n",
        "    if vertical_hist[0][i]<10:\r\n",
        "      start_matrix.append(i)\r\n",
        "\r\n",
        "  for i in range(len(start_matrix)-1):\r\n",
        "    if start_matrix[i+1]-start_matrix[i]<10:\r\n",
        "      delete_matrix.append(i)\r\n",
        "  \r\n",
        "  for i in range(len(start_matrix)):\r\n",
        "    count=0\r\n",
        "    for j in range(len(delete_matrix)):\r\n",
        "      if  i==delete_matrix[j]:\r\n",
        "        count=count+1\r\n",
        "    if count==0:\r\n",
        "      address_matrix.append(start_matrix[i])\r\n",
        "\r\n",
        "\r\n",
        "  for i in range(len(address_matrix)-1):\r\n",
        "    dissection_matrix.append([address_matrix[i],address_matrix[i+1]])\r\n",
        "  for i in range(len(dissection_matrix)):\r\n",
        "    characters.append(img[0:m,dissection_matrix[i][0]:dissection_matrix[i][1]])\r\n",
        "    \r\n",
        "    \r\n",
        "  return characters"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66QIUDBRwuHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f52c8d-73e3-4e36-d06c-f9b943c3861b"
      },
      "source": [
        "directory='/content/data-directory'\r\n",
        "def data_label():\r\n",
        "\r\n",
        "  samples=[]\r\n",
        "  labels=[]\r\n",
        "\r\n",
        " \r\n",
        "  \r\n",
        " \r\n",
        "  \r\n",
        "  \r\n",
        "  \r\n",
        "  for filename in os.listdir(directory):\r\n",
        "    count=0\r\n",
        "    text=open('/content/lines_new.txt')\r\n",
        "    image_orig=Image.open('/content/data-directory/'+filename,'r')\r\n",
        "    img=image_binarization(image_orig)\r\n",
        "    lines=line_segmentation(img)\r\n",
        "    for line in text:\r\n",
        "      line_Split = line.strip().split(\" \")\r\n",
        "      filename_split=filename.split('.')\r\n",
        "      linesplit=line_Split[0].split(\"-\")\r\n",
        "      string= linesplit[0]+'-'+linesplit[1]\r\n",
        "      if string==filename_split[0]:\r\n",
        "          count=count+1\r\n",
        "    if count==len(lines): \r\n",
        "      for i in range(len(lines)):\r\n",
        "        try:\r\n",
        "          words=word_segmentation(lines[i])\r\n",
        "          text=open('/content/lines_new.txt')\r\n",
        "          for line in text:\r\n",
        "            lineSplit = line.strip().split(' ')\r\n",
        "              \r\n",
        "            filename_split=filename.split('.')\r\n",
        "            if lineSplit[0]==filename_split[0]+'-'+str(0)+str(i):\r\n",
        "              word_split = lineSplit[8].split('|')\r\n",
        "              if len(word_split)==len(words):\r\n",
        "                for j in range(len(words)):\r\n",
        "                  characters=char_segmentation(words[j])\r\n",
        "                  if len(word_split[j])==len(characters):\r\n",
        "                    for k in range(len(characters)):\r\n",
        "                      \r\n",
        "                      character=cv2.resize(characters[k],(96,96))\r\n",
        "                      samples.append(character)\r\n",
        "                    for l in word_split[j]:\r\n",
        "                      labels.append(l) \r\n",
        "\r\n",
        "        except ValueError as ve:\r\n",
        "            continue  \r\n",
        "          \r\n",
        "    \r\n",
        "  \r\n",
        "                 \r\n",
        "  \r\n",
        "  return  samples,labels\r\n",
        "\r\n",
        "samples,labels=data_label()\r\n",
        "print(len(samples))\r\n",
        "print(len(labels))\r\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8474\n",
            "8474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGn_zPL9B4S9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6518952e-45cf-4daf-a5cc-cc468ed22929"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "samples = np.array(samples, dtype='float' )/ 255.0\r\n",
        "labels = np.array(labels)\r\n",
        "lb = LabelBinarizer()\r\n",
        "labels = lb.fit_transform(labels)\r\n",
        "samples.shape\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8474, 96, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGJBpraTECo0",
        "outputId": "8f4f6fef-74ef-4418-d716-18d39bbfbe3d"
      },
      "source": [
        "samples = np.array(samples, dtype='float' )/ 255.0\r\n",
        "labels = np.array(labels)\r\n",
        "samples.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8474, 96, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCcWJ6DBczs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "trainx,testx,trainy,testy = train_test_split(samples, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbI-7-zFP7L"
      },
      "source": [
        "trainx=trainx.reshape(trainx.shape[0],96,96,1)\r\n",
        "testx=testx.reshape(testx.shape[0],96,96,1)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZG0xxcQCaE0"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation,Dropout,BatchNormalization\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras import utils as np_utils\r\n",
        "from tensorflow.keras import backend \r\n",
        "img_dims=(96,96,1)\r\n",
        "batch_size=64\r\n",
        "epoch=50\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4pQWmrPdweC"
      },
      "source": [
        "aug = ImageDataGenerator( rotation_range=25, width_shift_range=0.1, \r\n",
        "                         height_shift_range=0.1, shear_range=0.2,\r\n",
        "                         zoom_range=0.2, horizontal_flip=True,fill_mode='nearest')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtR57S5PbEDh"
      },
      "source": [
        "def build_model(height, width,depth, classes):\r\n",
        "  input_shape = (height, width, depth)\r\n",
        "  channel_dim = -1 # last position \r\n",
        "  if backend.image_data_format() == 'channels_first':\r\n",
        "    input_shape = (depth, height, width)\r\n",
        "    channel_dim = 1\r\n",
        "    \r\n",
        "  model = keras.models.Sequential()\r\n",
        "  # BLOCK1\r\n",
        "  model.add(Conv2D(32,(3,3),padding='same', input_shape=input_shape))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(MaxPooling2D(pool_size=(3, 3)))\r\n",
        "  \r\n",
        "\r\n",
        "  model.add(Conv2D(64,(3,3),padding='same'))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  \r\n",
        "  model.add(Dropout(0.25))\r\n",
        "\r\n",
        "  model.add(Conv2D(128,(3,3),padding='same'))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "  model.add(Dropout(0.25))\r\n",
        "  \r\n",
        "  model.add(Conv2D(256,(3,3),padding='same'))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "\r\n",
        "  model.add(Conv2D(512,(3,3),padding='same'))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "  model.add(Conv2D(1024,(3,3),padding='same'))\r\n",
        "  model.add(Activation('relu'))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "  \r\n",
        "  \r\n",
        "  \r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "  \r\n",
        "    \r\n",
        "\r\n",
        "   \r\n",
        "   \r\n",
        "   \r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "    # BLOCK 5\r\n",
        "  model.add(Flatten()) # this converts our 3D feature maps to 1D feature vectors\r\n",
        "  \r\n",
        "  model.add(Dense(1024))\r\n",
        "  model.add(Activation(\"relu\"))\r\n",
        "  model.add(BatchNormalization(axis=channel_dim))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "  \r\n",
        "  \r\n",
        "  \r\n",
        "  \r\n",
        "\r\n",
        "  model.add(Dense(classes))\r\n",
        "  model.add(Activation(\"softmax\"))\r\n",
        "  \r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "  return model\r\n",
        "\r\n",
        "trainx=trainx.reshape(trainx.shape[0],96,96,1)\r\n",
        "testx=testx.reshape(testx.shape[0],96,96,1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVZfoI5rd3tQ"
      },
      "source": [
        "epochs_needed=[]\r\n",
        "model =build_model(height=img_dims[0], width=img_dims[1],depth=img_dims[2],classes = len(lb.classes_))\r\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \r\n",
        "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\r\n",
        "\r\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "hist = model.fit(aug.flow(trainx, trainy, batch_size=batch_size),\r\n",
        "                 validation_data=(testx, testy),callbacks=[monitor],\r\n",
        "                 steps_per_epoch= len(trainx) // batch_size,\r\n",
        "                 epochs=100, verbose=1)\r\n",
        "epochs = monitor.stopped_epoch\r\n",
        "epochs_needed.append(epochs)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39AeC75AwX_7",
        "outputId": "49b41e3a-faa6-40d4-e95e-a40c7ea46c18"
      },
      "source": [
        "x=testx[1].reshape(1,testx[1].shape[0],testx[1].shape[1],testx[1].shape[2])\r\n",
        "a=np.argmax(model.predict(x), axis=-1)\r\n",
        "print(lb.classes_[a])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['h']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyK4V8T6ztdq"
      },
      "source": [
        "image_orig=Image.open('test.png','r')\r\n",
        "img=image_binarization(image_orig)\r\n",
        "lines=line_segmentation(img)\r\n",
        "string=[]\r\n",
        "for i in range(len(lines)):\r\n",
        "  try:\r\n",
        "    words=word_segmentation(lines[i])\r\n",
        "    \r\n",
        "    for j in range(len(words)):\r\n",
        "      characters=char_segmentation(words[j])\r\n",
        "      \r\n",
        "      for k in range(len(characters)):\r\n",
        "        character=cv2.resize(characters[k],(96,96))\r\n",
        "        \r\n",
        "        \r\n",
        "        x=character.reshape(1,96,96,1)\r\n",
        "        a=np.argmax(model.predict(x), axis=-1)\r\n",
        "        string.append(lb.classes_[a])\r\n",
        "\r\n",
        "\r\n",
        "  except ValueError as ve:\r\n",
        "    continue  \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          \r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}