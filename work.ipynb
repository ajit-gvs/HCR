{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPVeGfcJDay1yqwFD0LLy2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit-gvs/HCR/blob/master/work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlih4j_fnArf",
        "outputId": "9b2ebe0c-d0be-46c6-806b-d1584f02ec04"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.__version__)\r\n",
        "\r\n",
        "import cv2\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from PIL import Image\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from PIL import ImageFile\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "directory='/content/data-directory'\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGDFI8YMQrHB"
      },
      "source": [
        "def image_binarization(image):\r\n",
        "  # converting image to grayscale\r\n",
        "  image_grayscale=image.convert('L')\r\n",
        "  img=np.array(image_grayscale) \r\n",
        "   \r\n",
        "  img[img <128] = 0\r\n",
        "  img[img >=128] = 254 \r\n",
        "\r\n",
        "  #making white as foreground pixels and black as background pixels\r\n",
        "  img[img==0]=255\r\n",
        "  img[img==254]=0\r\n",
        "  \r\n",
        "  return img\r\n",
        "\r\n",
        "\r\n",
        "def line_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  end_matrix=[]\r\n",
        "\r\n",
        "  #matrix to get the start and end points of a line\r\n",
        "  \r\n",
        "  lines=[]\r\n",
        "  begin_matrix=[]\r\n",
        "  stop_matrix=[]\r\n",
        "  del_start_matrix=[]\r\n",
        "  del_end_matrix=[]\r\n",
        "\r\n",
        "  horizontal_hist = np.sum(img,axis=1,keepdims=True)/255\r\n",
        "  start_count=0\r\n",
        "\r\n",
        "  for i in range(len(horizontal_hist)):\r\n",
        "\r\n",
        "    if horizontal_hist[i]>0 and horizontal_hist[i-1]==0:\r\n",
        "      start_count+=1\r\n",
        "      start_matrix.append(i)\r\n",
        "\r\n",
        "    if horizontal_hist[i]==0 and start_count>0 and horizontal_hist[i-1]>0:\r\n",
        "      end_matrix.append(i)\r\n",
        "\r\n",
        "  \r\n",
        "  \r\n",
        "  if len(start_matrix)==len(end_matrix):\r\n",
        "    for i in range(len(start_matrix)):\r\n",
        "      if end_matrix[i]-start_matrix[i]<20:\r\n",
        "        del_start_matrix.append(i)\r\n",
        "        del_end_matrix.append(i)\r\n",
        "    for i in range(len(start_matrix)):\r\n",
        "      count=0\r\n",
        "      for j in range(len(del_start_matrix)):\r\n",
        "        if i==del_start_matrix[j]:\r\n",
        "          count=count+1\r\n",
        "      if count==0:\r\n",
        "        begin_matrix.append(start_matrix[i])\r\n",
        "    for i in range(len(end_matrix)):\r\n",
        "      count=0\r\n",
        "      for j in range(len(del_end_matrix)):\r\n",
        "        if i==del_end_matrix[j]:\r\n",
        "          count=count+1\r\n",
        "      if count==0:\r\n",
        "        stop_matrix.append(end_matrix[i])\r\n",
        "    \r\n",
        "    for i in range(len(begin_matrix)):\r\n",
        "      lines.append(img[begin_matrix[i]:stop_matrix[i],:])\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "  \r\n",
        "  return lines\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def word_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  end_matrix=[]\r\n",
        "\r\n",
        "  #matrix to get the start and end points of a word\r\n",
        "  dissection_matrix=[]\r\n",
        "  \r\n",
        "  words=[]\r\n",
        "  m,n=img.shape\r\n",
        "  \r\n",
        "  length=[]\r\n",
        "  vertical_hist = np.sum(img,axis=0,keepdims=True)/255\r\n",
        "  \r\n",
        "  \r\n",
        "  start_count=0\r\n",
        "  \r\n",
        "  \r\n",
        "  for i in range(len(vertical_hist[0])):\r\n",
        "    if vertical_hist[0][i]>0 and vertical_hist[0][i-1]==0:\r\n",
        "      start_count+=1\r\n",
        "      start_matrix.append(i)\r\n",
        "    if vertical_hist[0][i]==0 and start_count>0 and vertical_hist[0][i-1]>0:\r\n",
        "      end_matrix.append(i)\r\n",
        "  \r\n",
        "  \r\n",
        "  length_mag=0\r\n",
        "  for i in range(len(start_matrix)):\r\n",
        "    if i>0:\r\n",
        "      length_mag=(start_matrix[i]-end_matrix[i-1])\r\n",
        "      length.append(length_mag)\r\n",
        "\r\n",
        "  max=np.max(length)\r\n",
        "     \r\n",
        "  avg=max/3\r\n",
        "\r\n",
        "  dissection_matrix.append([start_matrix[0],end_matrix[0]])\r\n",
        "  j=0\r\n",
        "  for i in range(len(length)-1):\r\n",
        "    \r\n",
        "    if length[i]> avg:\r\n",
        "      dissection_matrix.append([start_matrix[i+1],end_matrix[i+1]])\r\n",
        "      j=j+1\r\n",
        "      \r\n",
        "    if length[i]<=avg:\r\n",
        "      dissection_matrix[j][1]=end_matrix[i+1]\r\n",
        "  for i in range(len(dissection_matrix)):\r\n",
        "    words.append(img[0:m,dissection_matrix[i][0]:dissection_matrix[i][1]])\r\n",
        "  \r\n",
        "  return words\r\n",
        "\r\n",
        "\r\n",
        "def char_segmentation(img):\r\n",
        "  start_matrix=[]\r\n",
        "  dissection_matrix=[]\r\n",
        "  delete_matrix=[]\r\n",
        "  address_matrix=[]\r\n",
        "  \r\n",
        "  \r\n",
        "  characters=[]\r\n",
        "  m,n=img.shape\r\n",
        "\r\n",
        "  vertical_hist = np.sum(img,axis=0,keepdims=True)/255\r\n",
        "  start_matrix.append(0)\r\n",
        "\r\n",
        "  for i in range(len(vertical_hist[0])):\r\n",
        "    if vertical_hist[0][i]<10:\r\n",
        "      start_matrix.append(i)\r\n",
        "\r\n",
        "  for i in range(len(start_matrix)-1):\r\n",
        "    if start_matrix[i+1]-start_matrix[i]<10:\r\n",
        "      delete_matrix.append(i)\r\n",
        "  \r\n",
        "  for i in range(len(start_matrix)):\r\n",
        "    count=0\r\n",
        "    for j in range(len(delete_matrix)):\r\n",
        "      if  i==delete_matrix[j]:\r\n",
        "        count=count+1\r\n",
        "    if count==0:\r\n",
        "      address_matrix.append(start_matrix[i])\r\n",
        "\r\n",
        "\r\n",
        "  for i in range(len(address_matrix)-1):\r\n",
        "    dissection_matrix.append([address_matrix[i],address_matrix[i+1]])\r\n",
        "  for i in range(len(dissection_matrix)):\r\n",
        "    characters.append(img[0:m,dissection_matrix[i][0]:dissection_matrix[i][1]])\r\n",
        "    \r\n",
        "    \r\n",
        "  return characters"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqeVmA-4Q1ZI",
        "outputId": "80e319b5-0558-48e6-e9a1-a65a25be9d29"
      },
      "source": [
        "def data_label():\r\n",
        "\r\n",
        "  samples=[]\r\n",
        "  labels=[]\r\n",
        "\r\n",
        " \r\n",
        "  \r\n",
        " \r\n",
        "  \r\n",
        "  \r\n",
        "  \r\n",
        "  for filename in os.listdir(directory):\r\n",
        "    count=0\r\n",
        "    text=open('/content/lines_new.txt')\r\n",
        "    image_orig=Image.open('/content/data-directory/'+filename,'r')\r\n",
        "    img=image_binarization(image_orig)\r\n",
        "    lines=line_segmentation(img)\r\n",
        "    for line in text:\r\n",
        "      line_Split = line.strip().split(\" \")\r\n",
        "      filename_split=filename.split('.')\r\n",
        "      linesplit=line_Split[0].split(\"-\")\r\n",
        "      string= linesplit[0]+'-'+linesplit[1]\r\n",
        "      if string==filename_split[0]:\r\n",
        "          count=count+1\r\n",
        "    if count==len(lines): \r\n",
        "      for i in range(len(lines)):\r\n",
        "        try:\r\n",
        "          words=word_segmentation(lines[i])\r\n",
        "          text=open('/content/lines_new.txt')\r\n",
        "          for line in text:\r\n",
        "            lineSplit = line.strip().split(' ')\r\n",
        "            filename_split=filename.split('.')\r\n",
        "            if lineSplit[0]==filename_split[0]+'-'+str(0)+str(i):\r\n",
        "              word_split = lineSplit[8].split('|')\r\n",
        "              if len(word_split)==len(words):\r\n",
        "                for j in range(len(words)):\r\n",
        "                  characters=char_segmentation(words[j])\r\n",
        "                  if len(word_split[j])==len(characters):\r\n",
        "                    for k in range(len(characters)):\r\n",
        "                      \r\n",
        "                      character=cv2.resize(characters[k],(28,28))\r\n",
        "                      samples.append(character)\r\n",
        "                    for l in word_split[j]:\r\n",
        "                      labels.append(l) \r\n",
        "\r\n",
        "        except ValueError as ve:\r\n",
        "          continue  \r\n",
        "          \r\n",
        "    \r\n",
        "  \r\n",
        "                 \r\n",
        "  \r\n",
        "  return  samples,labels\r\n",
        "\r\n",
        "samples,labels=data_label()\r\n",
        "print(len(samples))\r\n",
        "print(len(labels))\r\n",
        "for i in range(5):\r\n",
        "  print(labels[i])\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2891\n",
            "2891\n",
            "p\n",
            "o\n",
            "i\n",
            "n\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrphxdz7mdJh",
        "outputId": "570b606c-a21b-4e73-ac75-ac2c8214b8a5"
      },
      "source": [
        "samples = np.array(samples, dtype='float' )/ 255.0\r\n",
        "labels = np.array(labels)\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "lb = LabelBinarizer()\r\n",
        "labels = lb.fit_transform(labels)\r\n",
        "labels\r\n",
        "samples.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2891, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBhV7808m8W1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "trainx,testx,trainy,testy = train_test_split(samples, labels, test_size=0.2, random_state=42)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtjlO8gKnJvw"
      },
      "source": [
        "len(testx)\r\n",
        "testx.shape\r\n",
        "trainx=trainx.reshape(trainx.shape[0],28,28,1)\r\n",
        "testx=testx.reshape(testx.shape[0],28,28,1)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy11D-jbnRCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f41c857-95ea-4096-95ba-5d916a96b58e"
      },
      "source": [
        "HP_epoch = 100\r\n",
        "HP_init_lr = 1e-3 # learning_rate = 0.001\r\n",
        "HP_batch_size = 32\r\n",
        "HP_image_dims = (28,28,1)\r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpB3VJX2njXe"
      },
      "source": [
        "HP_model_path = 'bin/model'\r\n",
        "HP_binarized_labels = 'bin/labels'\r\n",
        "HP_metrics_storage = 'eval'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvwzhkSInwX1"
      },
      "source": [
        "aug = ImageDataGenerator( rotation_range=25, width_shift_range=0.1, \r\n",
        "                         height_shift_range=0.1, shear_range=0.2,\r\n",
        "                         zoom_range=0.2, horizontal_flip=True,fill_mode='nearest')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5snMGSkn9OX"
      },
      "source": [
        "from keras import backend\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Sequential\r\n",
        "#N= 5\r\n",
        "HP_block1_conv_dim = 32\r\n",
        "HP_block2_conv_dim = 64\r\n",
        "HP_block3_conv_dim = 128\r\n",
        "HP_block4_conv_dim = 256\r\n",
        "HP_block5_dense_dim = 1024\r\n",
        "HP_small_pattern = (3,3) # UNCOMPRESSED or 1-2 compression IMAGES\r\n",
        "HP_large_pattern = (2,2) # 4 times compressed images from previous MP layers!!!\r\n",
        "HP_dropout_little =0.25\r\n",
        "HP_dropout_big = 0.50\r\n",
        "# HP_epochs, batch_size-> are now problems of the developer USING this model. \r\n",
        "\r\n",
        "HP_img_dims = (28,28,1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT67XenZoE-m"
      },
      "source": [
        "class RacoonVGG:\r\n",
        "  @staticmethod\r\n",
        "  def build(height, width,depth, classes):\r\n",
        "    input_shape = (height, width, depth)\r\n",
        "    channel_dim = -1 # last position \r\n",
        "    if backend.image_data_format() == 'channels_first':\r\n",
        "      input_shape = (depth, height, width)\r\n",
        "      channel_dim = 1\r\n",
        "    model = Sequential()\r\n",
        "    # BLOCK1\r\n",
        "    model.add(Conv2D(HP_block1_conv_dim,HP_small_pattern, padding='same',\r\n",
        "                     input_shape=input_shape))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 2\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "    \r\n",
        "    # COMPLEX BLOCK 3\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 4\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # BLOCK 5- Image Classification (OBJECT)\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(HP_block5_dense_dim))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(HP_dropout_big))\r\n",
        "    model.add(Dense(classes))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "trainx=trainx.reshape(trainx.shape[0],28,28,1)\r\n",
        "testx=testx.reshape(testx.shape[0],28,28,1)\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqHD_2XsoUkd",
        "outputId": "128a1b78-d12a-4835-b179-809dd3837a2c"
      },
      "source": [
        "import keras\r\n",
        "import keras.utils\r\n",
        "from keras import utils as np_utils\r\n",
        "from keras.optimizers import adam\r\n",
        "model = RacoonVGG.build(height=HP_img_dims[0], width=HP_img_dims[1],depth=HP_img_dims[2],classes = len(lb.classes_))\r\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\r\n",
        "hist = model.fit(aug.flow(trainx, trainy, batch_size=HP_batch_size),\r\n",
        "                 validation_data=(testx, testy),\r\n",
        "                 steps_per_epoch= len(trainx) // HP_batch_size,\r\n",
        "                 epochs=HP_epoch, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/100\n",
            "72/72 [==============================] - 10s 133ms/step - loss: 5.1250 - accuracy: 0.0566 - val_loss: 3.7850 - val_accuracy: 0.0846\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 4.2301 - accuracy: 0.0959 - val_loss: 3.6014 - val_accuracy: 0.1364\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 3.7279 - accuracy: 0.1254 - val_loss: 3.5354 - val_accuracy: 0.0587\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 3.5099 - accuracy: 0.1254 - val_loss: 3.5066 - val_accuracy: 0.0587\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 3.3896 - accuracy: 0.1346 - val_loss: 3.4554 - val_accuracy: 0.1347\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.3414 - accuracy: 0.1557 - val_loss: 3.4901 - val_accuracy: 0.1641\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.3019 - accuracy: 0.1487 - val_loss: 3.2813 - val_accuracy: 0.1140\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.2308 - accuracy: 0.1526 - val_loss: 3.1170 - val_accuracy: 0.1883\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 3.2115 - accuracy: 0.1614 - val_loss: 3.0317 - val_accuracy: 0.1934\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.1786 - accuracy: 0.1671 - val_loss: 2.9379 - val_accuracy: 0.1934\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.1137 - accuracy: 0.1776 - val_loss: 3.0117 - val_accuracy: 0.2055\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.0821 - accuracy: 0.1749 - val_loss: 2.9675 - val_accuracy: 0.2142\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.0999 - accuracy: 0.1733 - val_loss: 2.9743 - val_accuracy: 0.2263\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.0705 - accuracy: 0.1895 - val_loss: 2.8794 - val_accuracy: 0.2366\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.0340 - accuracy: 0.1825 - val_loss: 2.8214 - val_accuracy: 0.2798\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 3.0175 - accuracy: 0.2023 - val_loss: 3.0053 - val_accuracy: 0.2867\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.9960 - accuracy: 0.2012 - val_loss: 3.2241 - val_accuracy: 0.2625\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.9465 - accuracy: 0.2053 - val_loss: 2.9081 - val_accuracy: 0.2504\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.9794 - accuracy: 0.2132 - val_loss: 2.9458 - val_accuracy: 0.2332\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.8889 - accuracy: 0.2268 - val_loss: 3.1119 - val_accuracy: 0.2487\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.8837 - accuracy: 0.2338 - val_loss: 3.0098 - val_accuracy: 0.2625\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.9219 - accuracy: 0.2110 - val_loss: 2.9728 - val_accuracy: 0.2919\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.8608 - accuracy: 0.2447 - val_loss: 2.8202 - val_accuracy: 0.3022\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.7996 - accuracy: 0.2374 - val_loss: 2.7827 - val_accuracy: 0.2712\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.8185 - accuracy: 0.2429 - val_loss: 2.9404 - val_accuracy: 0.2366\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.8494 - accuracy: 0.2430 - val_loss: 2.8549 - val_accuracy: 0.2712\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.8027 - accuracy: 0.2382 - val_loss: 2.8021 - val_accuracy: 0.2884\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.8355 - accuracy: 0.2465 - val_loss: 2.8100 - val_accuracy: 0.2867\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.7686 - accuracy: 0.2618 - val_loss: 3.2109 - val_accuracy: 0.3022\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.7648 - accuracy: 0.2390 - val_loss: 3.0820 - val_accuracy: 0.2832\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.7424 - accuracy: 0.2667 - val_loss: 2.9506 - val_accuracy: 0.3092\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.7838 - accuracy: 0.2417 - val_loss: 2.7505 - val_accuracy: 0.2798\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.7140 - accuracy: 0.2589 - val_loss: 2.8531 - val_accuracy: 0.2919\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6790 - accuracy: 0.2711 - val_loss: 2.9563 - val_accuracy: 0.3057\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6955 - accuracy: 0.2706 - val_loss: 2.9405 - val_accuracy: 0.3057\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6677 - accuracy: 0.2951 - val_loss: 2.8976 - val_accuracy: 0.3161\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.7451 - accuracy: 0.2649 - val_loss: 2.8203 - val_accuracy: 0.2556\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6209 - accuracy: 0.2855 - val_loss: 2.7598 - val_accuracy: 0.3299\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6279 - accuracy: 0.2754 - val_loss: 2.8090 - val_accuracy: 0.2850\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6899 - accuracy: 0.2646 - val_loss: 2.8015 - val_accuracy: 0.3178\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6475 - accuracy: 0.2804 - val_loss: 2.6529 - val_accuracy: 0.3282\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5904 - accuracy: 0.2895 - val_loss: 2.7919 - val_accuracy: 0.3195\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5477 - accuracy: 0.2978 - val_loss: 2.8813 - val_accuracy: 0.2988\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6436 - accuracy: 0.2741 - val_loss: 2.7272 - val_accuracy: 0.3143\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.6184 - accuracy: 0.2868 - val_loss: 2.6886 - val_accuracy: 0.2850\n",
            "Epoch 46/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4913 - accuracy: 0.3066 - val_loss: 2.7170 - val_accuracy: 0.3178\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5328 - accuracy: 0.3000 - val_loss: 2.7029 - val_accuracy: 0.3143\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.5598 - accuracy: 0.2838 - val_loss: 2.6951 - val_accuracy: 0.3212\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5338 - accuracy: 0.3004 - val_loss: 2.5820 - val_accuracy: 0.3316\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5432 - accuracy: 0.3000 - val_loss: 2.6033 - val_accuracy: 0.3402\n",
            "Epoch 51/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.5199 - accuracy: 0.3000 - val_loss: 2.7001 - val_accuracy: 0.3385\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.4781 - accuracy: 0.3061 - val_loss: 2.6714 - val_accuracy: 0.3299\n",
            "Epoch 53/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4811 - accuracy: 0.3123 - val_loss: 2.6850 - val_accuracy: 0.3523\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.4060 - accuracy: 0.3382 - val_loss: 2.6752 - val_accuracy: 0.3765\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4899 - accuracy: 0.3101 - val_loss: 2.5786 - val_accuracy: 0.3230\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4516 - accuracy: 0.3268 - val_loss: 2.7041 - val_accuracy: 0.3368\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.4483 - accuracy: 0.3241 - val_loss: 2.6199 - val_accuracy: 0.3610\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4469 - accuracy: 0.3263 - val_loss: 2.6768 - val_accuracy: 0.3420\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4304 - accuracy: 0.3224 - val_loss: 2.6311 - val_accuracy: 0.3299\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3851 - accuracy: 0.3307 - val_loss: 2.6065 - val_accuracy: 0.3385\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.4080 - accuracy: 0.3302 - val_loss: 2.5947 - val_accuracy: 0.3420\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 2.4076 - accuracy: 0.3316 - val_loss: 2.6448 - val_accuracy: 0.3351\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3558 - accuracy: 0.3338 - val_loss: 2.6684 - val_accuracy: 0.3368\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.3336 - accuracy: 0.3447 - val_loss: 2.4979 - val_accuracy: 0.3834\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3433 - accuracy: 0.3372 - val_loss: 2.6927 - val_accuracy: 0.3402\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.3161 - accuracy: 0.3557 - val_loss: 2.5763 - val_accuracy: 0.3644\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3862 - accuracy: 0.3425 - val_loss: 2.5109 - val_accuracy: 0.3851\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3391 - accuracy: 0.3382 - val_loss: 2.5496 - val_accuracy: 0.3420\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3227 - accuracy: 0.3515 - val_loss: 2.5348 - val_accuracy: 0.3817\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3032 - accuracy: 0.3403 - val_loss: 2.5814 - val_accuracy: 0.3454\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.3065 - accuracy: 0.3583 - val_loss: 2.5179 - val_accuracy: 0.3731\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.3324 - accuracy: 0.3478 - val_loss: 2.5455 - val_accuracy: 0.3489\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.3172 - accuracy: 0.3601 - val_loss: 2.7288 - val_accuracy: 0.2953\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 2.3390 - accuracy: 0.3399 - val_loss: 2.5906 - val_accuracy: 0.3644\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2778 - accuracy: 0.3627 - val_loss: 2.5735 - val_accuracy: 0.3402\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2730 - accuracy: 0.3570 - val_loss: 2.5076 - val_accuracy: 0.3851\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2145 - accuracy: 0.3702 - val_loss: 2.4553 - val_accuracy: 0.3679\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.2216 - accuracy: 0.3649 - val_loss: 2.5664 - val_accuracy: 0.3627\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.2082 - accuracy: 0.3789 - val_loss: 2.7059 - val_accuracy: 0.3489\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1874 - accuracy: 0.3746 - val_loss: 2.7667 - val_accuracy: 0.3333\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2489 - accuracy: 0.3833 - val_loss: 2.6097 - val_accuracy: 0.3506\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.2240 - accuracy: 0.3662 - val_loss: 2.5818 - val_accuracy: 0.3523\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.1350 - accuracy: 0.3780 - val_loss: 2.5549 - val_accuracy: 0.3644\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1625 - accuracy: 0.3865 - val_loss: 2.5764 - val_accuracy: 0.3748\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2211 - accuracy: 0.3737 - val_loss: 2.9977 - val_accuracy: 0.3264\n",
            "Epoch 86/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1602 - accuracy: 0.3930 - val_loss: 2.4840 - val_accuracy: 0.3851\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.2100 - accuracy: 0.3706 - val_loss: 2.5374 - val_accuracy: 0.3731\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1749 - accuracy: 0.3724 - val_loss: 2.5316 - val_accuracy: 0.3800\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1314 - accuracy: 0.3952 - val_loss: 2.5500 - val_accuracy: 0.3834\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1618 - accuracy: 0.3873 - val_loss: 2.5020 - val_accuracy: 0.3869\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.1382 - accuracy: 0.3917 - val_loss: 2.6804 - val_accuracy: 0.3402\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 2.1688 - accuracy: 0.3855 - val_loss: 2.5597 - val_accuracy: 0.3472\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0965 - accuracy: 0.3943 - val_loss: 2.6021 - val_accuracy: 0.3679\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1146 - accuracy: 0.3859 - val_loss: 2.5976 - val_accuracy: 0.3748\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.1120 - accuracy: 0.3879 - val_loss: 2.5098 - val_accuracy: 0.3765\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0703 - accuracy: 0.3943 - val_loss: 2.5137 - val_accuracy: 0.3610\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0773 - accuracy: 0.4013 - val_loss: 2.4941 - val_accuracy: 0.3713\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0389 - accuracy: 0.4048 - val_loss: 2.4976 - val_accuracy: 0.3800\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0658 - accuracy: 0.4092 - val_loss: 2.5607 - val_accuracy: 0.3731\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 2.0648 - accuracy: 0.3989 - val_loss: 2.5352 - val_accuracy: 0.3765\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}